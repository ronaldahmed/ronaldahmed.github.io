---
layout: base
title: Code
---

        <!-- Page Content -->
        <div id="page-content-wrapper">
            <div class="container-fluid">
                <h1>Code &amp; Datasets</h1>
                <p>Check my repositories at <a href="https://github.com/ronaldahmed">github</a>!
                <div class="row">

                    <div class="col-lg-12">
                        <h2>Datasets</h2>
                        <ul>
                            <li>
                                <h3>Job Ad corpus annotated for Name Entity Recognition tasks.</h3>
                                <p>
                                Consisting of 800 job ads, each one tokenized and manually annotated with POS tag information (EAGLE format for Spanish data) and Entity Label in BIO format. Details in this <a href="https://www.researchgate.net/publication/284156153_Panorama_of_the_market_demand_for_mechanical_engineers_in_South_American_countries">paper</a>.<br>
                                [<a href="https://github.com/ronaldahmed/labor-market-demand-analysis/blob/master/annotated%20data.zip">link to repo</a>]
                                </p>
                            </li>

                            <li>
                                <h3>Entities extracted from Job Ads corpus.</h3>
                                <p>
                                Consisting of nearly 9000 job ads sampled from the database, tokenized and filtered from low-frequency words and tokens of no interest (phone numbers, salary, office hours, emails, urls). Then, the shallow parsers extract the relevant phrases. Dataset used in the topic model part of <a href="http://ronaldahmed.github.io/papers/shallow_parsing_topic_models.pdf">this paper</a>.<br>
                                [<a href="https://github.com/ronaldahmed/labor-market-demand-analysis">link to repo</a>]
                                </p>
                            </li>
                            <li>
                                <h3>Complete preprocessed Job Ads corpus</h3>
                                <p>
                                More than 900k job ads extracted from popular Latin American job-hunting websites. The NLTK tokenizer was extended to capture technical words typical of these kind of advertisement. [available upon request]<br>
                                </p>
                            </li>
                        </ul>
                    </div>


                    <div class="col-lg-12">
                        <h2>Code</h2>
                        <ul>
                            <li>
                                <h3>Labor market analysis using Topic Models and Shallow Parsing</h3>
                                [<a href="https://github.com/ronaldahmed/labor-market-demand-analysis">code</a>]
                                <p>
                                Analysis of the skills expected in engineers in Peruvian industry. Topic models are used to examine the relationship between requirements and functions, previously extracted by a Shallow Parser.All data was extracted from job-hunting websites, preprocessed and manually annotated.<br>
                                Interactive data visualizations and results explorer are available in these links:
                                <ul>
                                    <li>Labor market demand treemap for all professional majors in Peru. [<a href="http://www.empleatron.com/peru/nueva-data/treemap">link</a>]</li>
                                    <li>Labor market demand treemap for engineering majors for <a href="http://www.empleatron.com/peru/engineering/treemap">Peru</a>, <a href="http://www.empleatron.com/chile/engineering/treemap">Chile</a>, and <a href="http://www.empleatron.com/colombia/engineering/treemap">Colombia</a>.</li>
                                    <li>Relationship between all professional majors in Peru. [<a href="http://www.empleatron.com/peru/nueva-data/circleplot">link</a>]</li>
                                    <li>Relationship between engineering majors in <a href="http://www.empleatron.com/peru/engineering/circleplot">Peru</a>, <a href="http://www.empleatron.com/chile/engineering/circleplot">Chile</a>, and <a href="http://www.empleatron.com/colombia/engineering/circleplot">Colombia</a>.</li>
                                    <li>Topic content browser, based on the work of <a href="http://www.cs.princeton.edu/~achaney/projects/papers/ChaneyBlei2012.pdf">Chaney and Blei</a>. [<a href="http://www.empleatron.com/peru/browser/">link</a>]</li>
                                </ul>
                                </p>
                            </li>

                            <li>
                                <h3>Rule-based professional major extractor</h3>
                                [<a href="https://github.com/ronaldahmed/labor-market-demand-analysis/tree/master/major_extractor">code</a>]
                                <p>
                                Professional majors requested in job ads are extracted using regular expressions.
                                </p>
                            </li>
                            <li>
                                <h3>Simultaneus Localization and Mapping for mobile ground robots</h3>
                                [<a href="https://github.com/ronaldahmed/SLAM-for-ugv">code</a>]
                                <p>
                                SLAM simulation for Ackerman mobile robots using EKF and particle filters, testing landmarks maps and occupancy grid maps of university facilities.
                                </p>
                            </li>
                            <li>
                                <h3>Path planning for mobile ground robots</h3>
                                [<a href="https://github.com/ronaldahmed/SLAM-for-ugv/tree/master/path-planning">code</a>]
                                <p>
                                Path planning for Ackerman mobile robots using A* algorithm. Tested for an HPI Racing Buggy (a scaled sand car), at indoor environments.
                                </p>
                            </li>

                        </ul>

                        
                        
                    </div>

                    
                </div>
            </div>
        </div>
        <!-- /#page-content-wrapper -->
